---
title: 구조화된 로깅 전략 설계
tags: [개인 프로젝트, 로깅, 구조화 로깅, MDC, 분산 추적]
date: 2026-02-14
---

## 프로젝트 요약

- **한 줄 요약**: SLF4J 기반 평문 로깅에서 JSON 구조화 로깅으로 전환하여 디버깅·모니터링·분산 추적을 개선하기 위한 전략 수립
- **키워드**: `JSON 로깅`, `MDC`, `logstash-logback-encoder`, `분산 추적`, `로그 마스킹`, `Loki`

## 문제(AS-IS)

- SLF4J만 사용 중이며, 로그가 평문(plain text) 형식으로 출력됨
- 로그 레벨/구조화 전략이 없어 디버깅·모니터링 시 파싱·검색이 어려움
- 요청 단위 추적(traceId, spanId)이 없어 분산 환경에서 요청 흐름 추적 불가
- 민감 정보(비밀번호, 토큰 등) 로그 노출 위험에 대한 대응 전략 부재
- 로그 수집/중앙화 파이프라인(Loki 계획은 있으나) 미구현

## 목표(TO-BE)

1. JSON 형식의 구조화 로깅으로 로그 파싱·검색 용이성 확보
2. 환경별(dev/staging/prod) 로그 레벨·출력 형식 전략 수립
3. 로그 필드 표준화(timestamp, level, message, traceId, spanId 등)
4. MDC 기반 traceId/spanId로 분산 추적 가능하게 구성
5. 민감 정보 마스킹 규칙 수립
6. 로그 수집 스택 선택 및 연동 방향 결정
7. HTTP Request 컨텍스트 로깅(method, path, status, duration 등)
8. User/Client 컨텍스트 로깅(user_id, client_ip, user_agent 등)
9. WebSocket 컨텍스트 로깅(session_id, destination 등)

## 설계/선택(Key decisions)

(구현 후 채울 예정)

## 결과(Impact)

(구현 후 채울 예정)

---

## 구현 상세

### 1) JSON 형식의 구조화 로깅으로 로그 파싱·검색 용이성 확보

**배경**: 현재 Spring Boot 기본 Logback으로 평문 로그가 출력됨. 로그 수집(Loki 등)과 연동하려면 파싱 가능한 형식이 필요함. 목적은 로깅 인프라에서 파싱·검색·트레이스 연동을 쉽게 하는 것.

- **(후보1) stdout JSON (Logback 내장 JsonEncoder)**
  - (장점1) 추가 의존성 없음
  - (장점2) 구현 단순
  - (장점3) `kubectl logs`로 바로 확인 가능
  - (장점4) Promtail/Filebeat와 자연스럽게 연동
  - (단점1) 필드 on/off 위주, 커스터마이징 제한적
  - (단점2) trace_id는 MDC 별도 주입 필요
- **(후보2) stdout JSON (logstash-logback-encoder)**
  - (장점1) 후보 1의 장점 3, 4 포함
  - (장점2) 필드명·패턴·마스킹 등 커스터마이징 풍부
  - (장점3) ELK/Loki 연동 최적화
  - (단점1) 추가 의존성 필요
  - (단점2) trace_id는 MDC 별도 주입 필요
- **(후보3) OTel OTLP (OpenTelemetryAppender)**
  - (장점1) 앱에서 JSON 불필요
  - (장점2) trace_id 자동 부착
  - (장점3) 로그·트레이스·메트릭 통합
  - (단점1) Collector 필수, 설정 복잡
  - (단점2) 로그 처리 시 Collector 부하 큼(후보 1·2 대비)
    - Collector가 없는 경우(후보 1·2): 앱 → stdout → Promtail/Filebeat가 pull → Loki. Collector 경유 없음.
    - Collector가 있는 경우(후보 3): 앱 → OTLP push → Collector 수신·파싱·전달 → Loki. Collector가 로그 처리량 병목(항목당 비용 커서 동일 리소스에서 수~십 건/sec 수준).
  - (단점3) stdout에 로그 없어 디버깅 어려움

**결정**: stdout JSON (logstash-logback-encoder)
- 필드명·패턴·마스킹 등 커스터마이징 풍부
- 목표 5번(민감 정보 마스킹)에 적합
- Collector 경유 없어 로그 처리 성능 우수(후보 3 대비)
- trace_id는 목표 4번(MDC)에서 별도 처리

**적용 완료**: `build.gradle.kts` 의존성 추가, `logback-spring.xml` 생성

### 2) 환경별(dev/staging/prod) 로그 레벨·출력 형식 전략 수립

**적용 완료**: `LOGGING_FORMAT` 환경변수로 출력 형식 지정(json/plain). `application.properties`의 `logging.format=${LOGGING_FORMAT:json}`, `default.env`에 항목 추가.

### 3) MDC 기반 traceId/spanId로 분산 추적 가능하게 구성

**목적**: 요청 단위로 로그를 묶어 추적 가능하게 함. Loki 등에서 `trace_id`로 검색 시 동일 요청의 모든 로그를 한 번에 조회.

**처리 방안 후보**:
- **(후보1) 수동 MDC (Filter)**
  - (장점1) 추가 의존성 없음
  - (장점2) 구현 단순, Filter에서 UUID 생성 후 MDC.put/clear
  - (단점1) spanId는 단일 요청이라 생략 가능, 분산 추적 시 수동 전파 필요
- **(후보2) OTel Java Agent**
  - (장점1) trace_id/span_id 자동 주입, 코드 변경 없음
  - (장점2) W3C Trace Context 표준 준수
  - (단점1) Agent JAR 추가, `-javaagent` 실행 방식 변경 필요
- **(후보3) Micrometer Tracing**
  - (장점1) trace_id/span_id 자동 주입, Spring Boot 3.x 네이티브
  - (장점2) W3C Trace Context 표준 준수
  - (장점3) Zipkin/Tempo 연동 시 유리
  - (단점1) Brave 등 의존성 추가

**결정**: Micrometer Tracing (후보3)
- trace_id/span_id 자동 주입, W3C 표준 준수
- 의존성 1개·설정 1줄·코드 0줄로 도입 부담 낮음
- 향후 Zipkin/Tempo 연동 시 즉시 활용 가능

**적용 완료**: `build.gradle.kts`에 `micrometer-tracing-bridge-brave` 추가, `application.properties`에 tracing 설정, `logback-spring.xml`의 LogstashEncoder가 MDC(traceId/spanId)를 JSON에 포함

### 4) MDC(traceId/spanId) 전파 추가 설정

**목적**: 비동기나 Websocket등 에서도 trace_id로 추적 가능하게 함.

**기술적 배경**:
- 동일 요청에서 파생된 작업은 traceId 유지(parent-child)가 표준(W3C Trace Context)
  - 다만, 메시지 큐 consumer처럼 시간·서비스가 분리되면 span link로 별도 trace를 연결
- MDC는 ThreadLocal 기반이라 스레드가 바뀌면 traceId/spanId가 사라짐
- 따라서 아래와 같은 상황에서 context가 끊김: 
  - 비동기 프로세스: @Async, Executor, CompletableFuture.supplyAsync(), AsyncRunner.runAsync/supplyAsync
  - Kotlin 코루틴 (추후 도입시)
  - WebSocket 메시지(clientInboundChannel)
  - @Scheduled, ThreadPoolTaskScheduler(WebSocket heartbeat·세션 만료 등, 요청 context 없음)
  - Redisson topic listener(외부 라이브러리 스레드)


**처리1: 비동기 프로세스**
- AsyncConfig.taskExecutor에 ContextPropagatingTaskDecorator 적용
- @Async, AsyncRunner.runAsync/supplyAsync에서 traceId/spanId 전파

**처리2: WebSocket 메시지(clientInboundChannel)**
- clientInboundChannel용 ChannelInterceptor 추가(가장 먼저 등록)
- preSend에서 Tracer로 span 생성·MDC 설정, afterSendCompletion에서 MDC clear
- 적용 완료: WebSocketTracingChannelInterceptor 생성, WebSocketConfig에 첫 번째 인터셉터로 등록

**처리3: @Scheduled, ThreadPoolTaskScheduler**
- SpanRunner: trace context 없는 실행에서 `runWithSpan(name) { ... }` / `supplyWithSpan(name) { ... }`로 span 생성·MDC 설정·정리
- ScheduledSpanAspect: @Scheduled 메서드에 span 자동 적용
- TaskScheduler 분리: AsyncConfig에 taskScheduler(primary, @Scheduled용) · WebSocketTaskSchedulerConfig에 webSocketBrokerTaskScheduler(SimpleBroker heartbeat)
- WebSocketSessionExpiryHeartbeatTask: @Scheduled로 전환, 필요 시 @Async로 taskExecutor에서 실행

**처리4: Redisson topic listener** ✅
- Redisson addListener 콜백은 Redisson 내부 스레드에서 실행되어 trace context 없음
- 적용: AsyncRunner.runAsync로 콜백 본문을 비동기 실행 → Redisson 스레드 즉시 반환, taskExecutor에서 SpanRunner.runWithSpan + publishEvent 처리
- (추후) MessageCommandEvent에 traceparent 포함 시 publisher→subscriber trace 연속 가능

### 5) 민감 정보 마스킹 규칙 수립

**목적**: 로그에 비밀번호, 토큰, 시크릿 등 민감 정보가 노출되지 않도록 마스킹 규칙을 적용함.

**기술적 배경**:
- logstash-logback-encoder 7.0+는 `MaskingJsonGeneratorDecorator`로 JSON 출력 시점에 마스킹 지원
- 마스킹 방식: (1) 필드 기반(FieldMasker) – JSON 필드명/경로로 전체 값 마스킹, (2) 값 기반(ValueMasker) – 정규식으로 값 내 패턴 마스킹

**처리 방안 후보**:
- **(후보1) 필드 기반 마스킹(PathMask / FieldNameBasedFieldMasker)**
  - (장점1) 추가 의존성 없음, logstash-logback-encoder 내장
  - (장점2) 필드명만 지정하면 전체 값 마스킹, 성능 우수
  - (단점1) MDC·structured argument 등 JSON 필드에만 적용
  - (단점2) message 필드 내 `password=xxx` 같은 부분 문자열은 마스킹 불가
- **(후보2) 값 기반 마스킹(RegexValueMasker)**
  - (장점1) message 등 필드 값 내 패턴 마스킹 가능
  - (단점1) 정규식 매칭 비용, 로그량 많을 때 성능 영향
  - (단점2) 패턴 설계·유지보수 부담
- **(후보3) 서드파티(logstash-logback-sensitive-data-obfuscator 등)**
  - (장점1) 사전 정의된 패턴 제공
  - (단점1) 추가 의존성, 프로젝트 요구에 맞지 않을 수 있음

**결정**: 필드 기반 마스킹(후보1) 우선 적용
- MDC·structured argument에 들어가는 민감 필드(password, token, authorization 등)를 필드명으로 마스킹
- message 내부 패턴 마스킹은 필요 시 RegexValueMasker로 추후 확장

**마스킹 대상 필드(예시)**:
- `password`, `secret`, `token`, `accessToken`, `refreshToken`
- `authorization`, `cookie`, `apiKey`, `api_key`
- (선택) `db_password`, `redis_password` – 설정 로깅 시

**구현 방식**:
- `logback-spring.xml`의 LogstashEncoder에 `jsonGeneratorDecorator`로 `MaskingJsonGeneratorDecorator` 추가
- `addPath()` 또는 `addPaths()`로 마스킹할 필드명 지정
- 기본 마스크값: `****` (변경 가능)

**적용 완료**: `logback-spring.xml`의 LogstashEncoder에 `jsonGeneratorDecorator`로 `MaskingJsonGeneratorDecorator` 추가. 마스킹 대상: password, secret, token, accessToken, refreshToken, authorization, cookie, apiKey, api_key